{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to analyze sanitation data\n",
    "\n",
    "\"\"\"\n",
    "Here are codes used by state inspectors when they determine\n",
    "a restaurant has sanitation violations. This is taken from\n",
    "http://www.myfloridalicense.com/DBPR/hotels-restaurants/inspections/inspection-dispositions/\n",
    "\n",
    "\n",
    "Facility Temporarily Closed:\n",
    "Operations ordered stopped until violations are corrected\n",
    "The inspector recommended closing the facility immediately\n",
    "after finding conditions that may endanger the health and\n",
    "safety of the public.\n",
    "\n",
    "Dispositions included in this result are:\n",
    "\n",
    " \tColLetter\tDescription\tVioNum\tRisk_factor\tPrimary_concern\n",
    "30\tAE\tBare hand contact with RTE food; Alternative Operating Procedure (AOP)\t9\tY\tN\n",
    "32\tAG\tEmployee health knowledge; ill/symptomatic employee present\t11\tY\tN\n",
    "33\tAH\tHands washed and clean, good hygienic practices, eating / drinking /smoking\t12\tY\tN\n",
    "37\tAL\tDishwashing facilities; chemical test kit(s); gauges\t16\tN\tY\n",
    "43\tAR\tFood-contact surfaces clean and sanitized\t22\tY\tN\n",
    "48\tAW\tWater source safe, hot (100Â°F) and cold under pressure\t27\tN\tY\n",
    "52\tBA\tHand wash sinks, hand washing supplies and hand wash sign\t31\tY\tN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# Set up connection to database.\n",
    "\n",
    "imacpath = \"/Users/rayd/workspace/flinsp/datafiles/\"\n",
    "airpath = \"/Users/Doug/workspace/flinsp/datafiles/\"\n",
    "dbfile = \"rinspect031120.sqlite\"\n",
    "dbpath = imacpath + dbfile\n",
    "conn = sqlite3.connect(dbpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 735 restaurants closed on first inspection.\n",
      "\n",
      "There were 246 remained closed on subsequent inspection.\n",
      "\n",
      "There were 543 cleared and opened by subsequent inspection.\n",
      "\n",
      "There were 143 reopened but will need another inspection.\n",
      "\n",
      "735 + 246 + 543 + 143 +  = 1667\n",
      "\n",
      "There were 1667 that had some word like 'emergency'.\n",
      "\n",
      "So it looks like we got them all.\n"
     ]
    }
   ],
   "source": [
    "# Make a list of visitid numbers for restaurants shut down\n",
    "# by inspectors.\n",
    "\n",
    "conn.row_factory = lambda cursor, row: row[0]\n",
    "c = conn.cursor()\n",
    "\n",
    "# on initial inspection\n",
    "vids = c.execute(\"SELECT visitid FROM fdinsp WHERE inspdispos = 'Emergency order recommended'\").fetchall()\n",
    "\n",
    "# remained shut on subsequent inspection\n",
    "vids2 = c.execute(\"SELECT visitid FROM fdinsp WHERE inspdispos = 'Emergency Order Callback Not Complied'\").fetchall()\n",
    "\n",
    "# Make pandas dataframe for both sets\n",
    "\n",
    "conn = sqlite3.connect(dbpath)\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM fdinsp WHERE inspdispos = 'Emergency order recommended';\", conn)\n",
    "df2 = pd.read_sql_query(\"SELECT * FROM fdinsp WHERE inspdispos = 'Emergency Order Callback Not Complied';\", conn)\n",
    "\n",
    "# Test to see if our dataset is complete\n",
    "\n",
    "count1 = df.shape\n",
    "count2 = df2.shape\n",
    "print(\"There were \" + str(count1[0]) + \" restaurants closed on first inspection.\")\n",
    "print(\"\\nThere were \" + str(count2[0]) + \" remained closed on subsequent inspection.\")\n",
    "\n",
    "# Contains 'Emergency' but means reopened\n",
    "df_test1 = pd.read_sql_query(\n",
    "    \"SELECT * FROM fdinsp WHERE inspdispos = 'Emergency Order Callback Complied';\", conn\n",
    "    )\n",
    "count3 = df_test1.shape\n",
    "print(\"\\nThere were \" + str(count3[0]) + \" cleared and opened by subsequent inspection.\")\n",
    "\n",
    "# Contains 'Emergency' but also means reopened\n",
    "df_test2 = pd.read_sql_query(\n",
    "    \"SELECT * FROM fdinsp WHERE inspdispos = 'Emergency Order Callback Time Extension';\", conn\n",
    "    )\n",
    "count4 = df_test2.shape\n",
    "print(\"\\nThere were \" + str(count4[0]) + \" reopened but will need another inspection.\")\n",
    "\n",
    "print(\"\\n\" +\n",
    "    str(count1[0]) + \" + \" +\n",
    "    str(count2[0]) + \" + \" +\n",
    "    str(count3[0]) + \" + \" +\n",
    "    str(count4[0]) + \" + \" +\n",
    "    \" = \" + str(count1[0] + count2[0] + count3[0] + count4[0])\n",
    "     )\n",
    "\n",
    "# Contains something like 'Emergency' but are there some where spelling or capitalization shifts?\n",
    "df_test3 = pd.read_sql_query(\"SELECT * FROM fdinsp WHERE inspdispos LIKE '%mergency%';\", conn)\n",
    "count5 = df_test3.shape\n",
    "print(\"\\nThere were \" + str(count5[0]) + \" that had some word like 'emergency'.\")\n",
    "\n",
    "print(\"\\nSo it looks like we got them all.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of dictionaries with detailed inspection reports\n",
    "# that led to closures\n",
    "\n",
    "def dict_factory(cursor, row):\n",
    "    dvio = {}\n",
    "    for idx, col in enumerate(cursor.description):\n",
    "        dvio[col[0]] = row[idx]\n",
    "    return dvio\n",
    "\n",
    "lvio = []\n",
    "lvio2 = []\n",
    "\n",
    "# initial closures\n",
    "for vid in vids:\n",
    "    con = sqlite3.connect(dbpath)\n",
    "    con.row_factory = dict_factory\n",
    "    cur = con.cursor()\n",
    "    cur.execute(f\"SELECT * FROM violations WHERE visitid = {vid}\")\n",
    "    lvio.extend(cur.fetchall())\n",
    "    con.close()\n",
    "\n",
    "# orders to remain closed\n",
    "for vid2 in vids2:\n",
    "    con = sqlite3.connect(dbpath)\n",
    "    con.row_factory = dict_factory\n",
    "    cur = con.cursor()\n",
    "    cur.execute(f\"SELECT * FROM violations WHERE visitid = {vid2}\")\n",
    "    lvio2.extend(cur.fetchall())\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitid</th>\n",
       "      <th>details_id</th>\n",
       "      <th>obs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>35A-05-4</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35A-04-4</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35A-03-4</td>\n",
       "      <td>270</td>\n",
       "      <td>270</td>\n",
       "      <td>270</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>03A-02-4</td>\n",
       "      <td>257</td>\n",
       "      <td>257</td>\n",
       "      <td>257</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35A-02-5</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31B-02-4</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31A-03-4</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>08B-38-4</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01B-02-4</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36-14-4</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  visitid  details_id  obs\n",
       "violation                               \n",
       "35A-05-4   304      304         304  304\n",
       "35A-04-4   288      288         288  288\n",
       "35A-03-4   270      270         270  270\n",
       "03A-02-4   257      257         257  257\n",
       "35A-02-5   195      195         195  195\n",
       "31B-02-4   150      150         150  150\n",
       "31A-03-4   129      129         129  129\n",
       "08B-38-4   125      125         125  125\n",
       "01B-02-4   123      123         123  123\n",
       "36-14-4    119      119         119  119"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dataframes with violation details\n",
    "\n",
    "df3 = pd.DataFrame(lvio) # Closed on initial inspection\n",
    "df4 = pd.DataFrame(lvio2) # Remained closed after follow-up\n",
    "\n",
    "# What was the most common violation in a closure inspection?\n",
    "\n",
    "df3g = df3.groupby('violation').count().sort_values(by=['visitid'], axis=0, ascending=False)\n",
    "\n",
    "# What were the most common violations in a closure inspection?\n",
    "\n",
    "df3.groupby('violation').count().sort_values(\n",
    "    by=['visitid'], axis=0, ascending=False\n",
    "    ).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stopsale = df3[df3.obs.str.contains(\"Stop Sale issued\")==True]\n",
    "df_stopsale.shape\n",
    "print(\"In the df of inspections using the summary reports that contained\")\n",
    "print(\"the words 'Emergency order recommended', we saw \" + str(count1[0]) + \" initial closures.\" )\n",
    "print(\"But in checking the detailed reports, we find \" + str(df_stopsale.shape[0]) + \" with 'Stop sale'\")\n",
    "print(\"Can you have a closure without a 'Stop sale'?\")\n",
    "print(\"Answers: Yes. 'Stop sale' refers to food item, maybe bad temp, not to the restaurant generally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we find which violations resulted in the most closures?\n",
    "\n",
    "# Violation codes and descriptions\n",
    "a = '35A-01-4' # Intermediate: Service animals\n",
    "b = '35A-02-5' # High priority: Live, small flying insects in food service area\n",
    "c = '35A-03-4' # Basic: Dead roaches on premesis\n",
    "d = '35A-04-4' # High priority: Rodent activity present as evidenced by droppings\n",
    "e = '35A-05-4' # High priority: Live roaches found\n",
    "f = '35A-06-4' # Basic: Accumulation of dead or trapped pests\n",
    "g = '35A-07-4' # High priority: Small flying insects in bar, kitchen, dumster, prep area\n",
    "h = '35A-09-4' # High priority: Presence of insects, rodents or other pests\n",
    "i = '35A-18-4' # High priority: Rodent rub marks present\n",
    "j = '35A-20-4' # Basic: Dead rodent present\n",
    "k = '35A-21-4' # High priority: Rodent burrow or nesting materials present\n",
    "l = '35A-23-4' # High priority: Rodent droppings present\n",
    "m = '03A-02-4' # High priority: Potentially hazardous  cold food held at greater than 41 degrees\n",
    "\n",
    "# Are there any closures that don't involve 35A-0*'?\n",
    "df3z = df3\n",
    "df3za = df3.groupby('visitid').filter(lambda x: all(a != i for i in x['violation']))\n",
    "df3zb = df3z.groupby('visitid').filter(lambda x: all(b != i for i in x['violation']))\n",
    "df3zc = df3z.groupby('visitid').filter(lambda x: all(c != i for i in x['violation']))\n",
    "df3zd = df3z.groupby('visitid').filter(lambda x: all(d != i for i in x['violation']))\n",
    "df3ze = df3z.groupby('visitid').filter(lambda x: all(e != i for i in x['violation']))\n",
    "df3zf = df3z.groupby('visitid').filter(lambda x: all(f != i for i in x['violation']))\n",
    "df3zg = df3z.groupby('visitid').filter(lambda x: all(g != i for i in x['violation']))\n",
    "df3zh = df3z.groupby('visitid').filter(lambda x: all(h != i for i in x['violation']))\n",
    "df3zi = df3z.groupby('visitid').filter(lambda x: all(i != i for i in x['violation']))\n",
    "df3zj = df3z.groupby('visitid').filter(lambda x: all(j != i for i in x['violation']))\n",
    "df3zk = df3z.groupby('visitid').filter(lambda x: all(k != i for i in x['violation']))\n",
    "df3zl = df3z.groupby('visitid').filter(lambda x: all(l != i for i in x['violation']))\n",
    "df3zm = df3z.groupby('visitid').filter(lambda x: all(m != i for i in x['violation']))\n",
    "\n",
    "#On checking database directly, this doesn't seem to work ....\n",
    "print(\"This approach finds whether, if a violation is present, it always\")\n",
    "print(\"results in a closure order:\")\n",
    "print(\"\\nThe number of closures on initial inspection = \" + str(df3z.shape[0]))\n",
    "print(\"\\nThe number of closures, despite this being found:\")\n",
    "print(\"'Service animals' = \" + str(df3za.shape[0]))\n",
    "print(\"'Live, small flying insects in food service area' = \" + str(df3zb.shape[0]))\n",
    "print(\"'Dead roaches on premesis' = \" + str(df3zc.shape[0]))\n",
    "print(\"'Rodent activity present as evidenced by droppings' = \" + str(df3zd.shape[0]))\n",
    "print(\"'Live roaches found' = \" + str(df3ze.shape[0]))\n",
    "print(\"'Accumulation of dead or trapped pests' = \" + str(df3zf.shape[0]))\n",
    "print(\"'Small flying insects in bar, kitchen, dumster, prep area' = \" + str(df3zg.shape[0]))\n",
    "print(\"'Presence of insects, rodents or other pests' = \" + str(df3zh.shape[0]))\n",
    "print(\"'Rodent rub marks present' = \" + str(df3zi.shape[0]))\n",
    "print(\"'Dead rodent present' = \" + str(df3zj.shape[0]))\n",
    "print(\"'Rodent burrow or nesting materials present' = \" + str(df3zk.shape[0]))\n",
    "print(\"'Rodent droppings present' = \" + str(df3zl.shape[0]))\n",
    "print(\"'Potentially hazardous  cold food held at greater than 41 degrees' = \" + str(df3zm.shape[0]))\n",
    "print(\"\\nSo, if 'Rodent rub marks present', the doors are closed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which counties had the most closures?\n",
    "# Calculated as closers per licensed restaurant\n",
    "\n",
    "# Count closures per county; these were closed on initial inspection.\n",
    "dfc = df.groupby('county').count()\n",
    "dfc = dfc.licnum.reset_index()\n",
    "dfc = dfc.rename(columns={'county' : 'county', 'licnum' : 'closures'})\n",
    "dfc = dfc.set_index('county')\n",
    "print(dfc)\n",
    "\n",
    "# Which counties are included in closures\n",
    "co_inc = list(df.groupby(['county']).groups.keys())\n",
    "\n",
    "#List of all Florida counties\n",
    "with open('outfiles/counties.txt', 'r') as f:\n",
    "    fl_counties = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "def diff(co_inc, fl_counties):\n",
    "    co_dif = [i for i in co_inc + fl_counties if i not in co_inc]\n",
    "    return co_dif\n",
    "\n",
    "missing_counties = diff(co_inc, fl_counties)\n",
    "\n",
    "print(\"\\nDid any counties not have closure orders in FY2018-19?\")\n",
    "print(\"\\nThese are not included: \" + str(', '.join(missing_counties)))\n",
    "print(\"\\nBut Miami-Dade listed simply as Dade in our data frame.\")\n",
    "\n",
    "missing = list(missing_counties)\n",
    "missing.remove('Miami-Dade')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv of licensed restaurants per county\n",
    "df_cntylic = pd.read_csv('datafiles/countycount.csv')\n",
    "df_cntylic = df_cntylic.drop(['Unnamed: 0'], axis=1)\n",
    "df_cntylic = df_cntylic[~df_cntylic['co_name'].isin(missing)] # drop missing counties\n",
    "df_cntylic= df_cntylic.rename(columns={\"lic_count\": \"licenses\", \"co_name\": \"county\"})\n",
    "df_cntylic = df_cntylic.set_index('county')\n",
    "\n",
    "# Closures per license\n",
    "dfc = df_cntylic.join(dfc) # join closures in each county with count of licenses in each county \n",
    "dfc['ratio'] = dfc.closures / dfc.licenses\n",
    "dfc['percent'] = dfc.ratio * 100\n",
    "dfc = dfc.sort_values(by=['ratio'])\n",
    "most_closed = dfc.sort_values(by=['ratio'], ascending=False).head(10)\n",
    "least_closed  = dfc.sort_values(by=['ratio'], ascending=True).head(10)\n",
    "dfc['ratio'] = dfc.closures / dfc.licenses\n",
    "dfc['percent'] = dfc.ratio * 100\n",
    "dfc = dfc.sort_values(by=['ratio'])\n",
    "most_closed = dfc.sort_values(by=['ratio'], ascending=False).head(10)\n",
    "least_closed  = dfc.sort_values(by=['ratio'], ascending=True).head(10)\n",
    "print(\"Counties as outliers for the most closures:\")\n",
    "print(most_closed.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Counties as outliers for the least closures:\")\n",
    "print(least_closed.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List restaurants by how many closures they had this year.\n",
    "\n",
    "# Drop unneeded columns\n",
    "dropcols = ['librow', 'inspnum', 'insptype', 'inspdispos', 'inspdate', 'totalvio', 'highvio', 'licid', 'visitid', 'time_now', 'time_posted']\n",
    "df_restaurants = df.drop(dropcols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count repeated closures per restaurant, listed by license number\n",
    "dupes = df_restaurants.pivot_table(index=['licnum'],aggfunc='size')\n",
    "dupes = dupes.reset_index()\n",
    "\n",
    "# Drop repeated rows so we can match with the dupes\n",
    "df_repeats = df_restaurants[df_restaurants.duplicated()]\n",
    "\n",
    "# Merge dataframes to get df with count of repeats\n",
    "dupes_count = pd.merge(df_repeats, dupes, on='licnum')\n",
    "dupes_count = dupes_count.sort_values(by=[0], ascending=False)\n",
    "dupes_count = dupes_count.drop_duplicates()\n",
    "isdupe = dupes_count[0]>1 # those with >1 closure\n",
    "dupes = dupes_count[isdupe] # filter for those >1 closure\n",
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure_csv(df_restaurants, lvio, lvio2):\n",
    "    \n",
    "    ''' Write all restaurants with initial closures to csv '''\n",
    "    \n",
    "    df_restaurants = df_restaurants.drop_duplicates()\n",
    "    df_restaurants.to_csv('outfiles/closedrestaurants.csv', index=False)\n",
    "\n",
    "    # Write csv file for violation details on initial closures\n",
    "    keys = lvio[0].keys\n",
    "    with open('outfiles/closurevios.csv', 'w', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=lvio[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(lvio)\n",
    "\n",
    "    # Write csv file for violation details on continued closures\n",
    "    keys = lvio2[0].keys\n",
    "    with open('outfiles/closurevios2.csv', 'w', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=lvio2[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(lvio2)\n",
    "\n",
    "response = input(\"Do you want to get a new csv file for restaurant closures: Y or N\")\n",
    "\n",
    "if response == \"Y\":\n",
    "    closure_csv(df_restaurants, lvio, lvio2)\n",
    "elif response == \"N\":\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
